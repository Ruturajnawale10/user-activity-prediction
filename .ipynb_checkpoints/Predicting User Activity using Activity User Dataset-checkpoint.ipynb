{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ab03e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x is feature dataset, y consists of class labels\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for k in range(1, 10):\n",
    "    path2 = \"data/a0\" + str(k) + \"/p\"\n",
    "    for j in range(1, 9):\n",
    "        path1 = path2 + str(j) + \"/s\"\n",
    "        for i in range(1, 10):\n",
    "            path = path1 + \"0\" + str(i) + \".txt\"\n",
    "            with open(path) as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    arr = line.split(\",\")\n",
    "                    arr = [float(measurement) for measurement in arr]\n",
    "                    x.append(arr)\n",
    "                    y.append(k)     #end numeric appended is activity label\n",
    "\n",
    "        for i in range(10, 61):\n",
    "            path = path1 + str(i) + \".txt\"\n",
    "            with open(path) as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    arr = line.split(\",\")\n",
    "                    arr = [float(measurement) for measurement in arr]\n",
    "                    x.append(arr)\n",
    "                    y.append(k)\n",
    "                    \n",
    "for k in range(10, 20):\n",
    "    path2 = \"data/a\" + str(k) + \"/p\"\n",
    "    for j in range(1, 9):\n",
    "        path1 = path2 + str(j) + \"/s\"\n",
    "        for i in range(1, 10):\n",
    "            path = path1 + \"0\" + str(i) + \".txt\"\n",
    "            with open(path) as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    arr = line.split(\",\")\n",
    "                    arr = [float(measurement) for measurement in arr]\n",
    "                    x.append(arr)\n",
    "                    y.append(k)\n",
    "\n",
    "        for i in range(10, 61):\n",
    "            path = path1 + str(i) + \".txt\"\n",
    "            with open(path) as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    arr = line.split(\",\")\n",
    "                    arr = [float(measurement) for measurement in arr]\n",
    "                    x.append(arr)\n",
    "                    y.append(k)\n",
    "\n",
    "#print(x[:10]) #125* 60* 8* 19 for 8 people and all activity\n",
    "#this x contains 1140000 rows and 46 columns. 45 columns are features and 46th column is activity label\n",
    "#print(y[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df09118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the modules necessary\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aff7c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using train_test_split to separate training and testing data\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5af000d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m standardScaler\u001b[38;5;241m.\u001b[39mfit(x_train) \n\u001b[1;32m      4\u001b[0m x_train \u001b[38;5;241m=\u001b[39m standardScaler\u001b[38;5;241m.\u001b[39mtransform(x_train)\n\u001b[0;32m----> 5\u001b[0m x_test \u001b[38;5;241m=\u001b[39m \u001b[43mstandardScaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:975\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    972\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    974\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m--> 975\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:924\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m<\u001b[39m ensure_min_features:\n\u001b[1;32m    918\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    919\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m feature(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    920\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m a minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    921\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_features, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_features, context)\n\u001b[1;32m    922\u001b[0m         )\n\u001b[0;32m--> 924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmay_share_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray_orig\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    925\u001b[0m     array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(array, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mmay_share_memory\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#standardizing the data improves the accuracy of model\n",
    "standardScaler = StandardScaler()\n",
    "standardScaler.fit(x_train) \n",
    "x_train = standardScaler.transform(x_train)\n",
    "x_test = standardScaler.transform(x_test)\n",
    "\n",
    "#using dimensional reduction results in poor accuracy, so we did not use it\n",
    "#pca\n",
    "# pca = PCA(n_components = 20)\n",
    "# pca.fit(x_train)\n",
    "# x_train = pca.transform(x_train)\n",
    "# x_test = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f603e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using KNN as the classification model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "y_predicted = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0863f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['sitting', 'standing', 'lying on back side', 'lying on right side', 'ascending stairs','descending stairs',\n",
    "          'standing in an elevator still', 'moving around in an elevator', 'walking in a parking lot',\n",
    "         'walking on a treadmill with a speed of 4 km/h in flat position', 'walking on a treadmill with a speed of 4 km/h in 15 deg inclined position',\n",
    "         'running on a treadmill with a speed of 8 km/h', 'exercising on a stepper',\n",
    "         'exercising on a cross trainer', 'cycling on an exercise bike in horizontal position', 'cycling on an exercise bike in vertical position',\n",
    "         'rowing', 'jumping', 'playing basketball']\n",
    "\n",
    "print(classification_report(y_test, y_predicted, target_names = labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85be849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3553ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before applying standardization of data\n",
    "\n",
    "#Before applying dimensional reduction PCA\n",
    "# accuracy = 0.9730701754385965 it gives same result as pca with all 45 features\n",
    "# accuracy = 0.9728859649122807 with n_components = 40\n",
    "\n",
    "#After applying dimensional reduction PCA\n",
    "# accuracy = 0.5351008771929825 with n_components = 2\n",
    "# accuracy = 0.6805263157894736 with n_components = 3\n",
    "# accuracy = 0.7498771929824561 with n_components = 4\n",
    "# accuracy = 0.8134736842105263 with n_components = 5\n",
    "# accuracy = 0.9730701754385965 with n_components = 45\n",
    "# accuracy = 0.9730701754385965 without pca. it gives same result as pca with all 45 features\n",
    "# accuracy = 0.9728859649122807 with n_components = 40\n",
    "\n",
    "\n",
    "\n",
    "#After applying standardization of data\n",
    "\n",
    "#Before applying dimensional reduction PCA\n",
    "# accuracy = 0.98975\n",
    "# accuracy =  with n_components = 40\n",
    "\n",
    "#After applying dimensional reduction PCA\n",
    "# accuracy =  with n_components = 2\n",
    "# accuracy =  with n_components = 3\n",
    "# accuracy =  with n_components = 4\n",
    "# accuracy = 0.9333947368421053 with n_components = 5\n",
    "# accuracy = 0.984561403508772 with n_components = 20\n",
    "# accuracy =  with n_components = 45\n",
    "# accuracy =  without pca. it gives same result as pca with all 45 features\n",
    "# accuracy =  with n_components = 40"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
